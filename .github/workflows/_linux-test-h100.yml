name: linux-test-h100
on:
  workflow_call:
    inputs:
      conda_env:
        required: True
        type: string
        description: |
          Conda environment to activate when testing Triton

jobs:
  linux-test-h100:
    if: github.repository_owner == 'pytorch-labs'
    runs-on: [gcp-h100-runner]
    timeout-minutes: 240
    environment: docker-s3-upload
    env:
      SETUP_SCRIPT: "/workspace/setup_instance.sh"
      CONDA_ENV: ${{ inputs.conda_env }}
    steps:
      - name: Checkout Tritonbench
        uses: actions/checkout@v3
        with:
          submodules: recursive
      - uses: dorny/paths-filter@v3
        id: submodules_changes
        with:
          filters: |
            fa:
              - 'submodules/flash-attention/**'
            xformers:
              - 'submodules/xformers/**'
      - name: Tune Nvidia GPU
        run: |
          sudo nvidia-smi -pm 1
          sudo ldconfig
          nvidia-smi
      - name: Reinstall flash-attn (optional)
        if: steps.submodules_changes.outputs.fa == 'true'
        run: |
          . "${SETUP_SCRIPT}"
          python install.py --fa2 --ci
          python install.py --fa3 --ci
      - name: Reinstall xformers (optional)
        if: steps.submodules_changes.outputs.xformers == 'true'
        run: |
          . "${SETUP_SCRIPT}"
          python install.py --xformers
      - name: Install Tritonbench
        run: |
          # speedup install and skip compile by reusing the docker .so files
          mkdir -p /workspace/tritonbench/.data
          ln -s /workspace/tritonbench/.data .
      - name: Test Tritonbench operators on H100 GPU
        run: |
          bash ./.ci/tritonbench/test-gpu.sh
